{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(unet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(64,64,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv3 = nn.Conv2d(64,128,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv4 = nn.Conv2d(128,128,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv5 = nn.Conv2d(128,256,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv6 = nn.Conv2d(256,256,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv7 = nn.Conv2d(256,512,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv8 = nn.Conv2d(512,512,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv9 = nn.Conv2d(512,1024,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv10 = nn.Conv2d(1024,1024,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.convtrans1 = nn.ConvTranspose2d(1024,512,2) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv11 = nn.Conv2d(1024,512,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv12 = nn.Conv2d(512,512,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(512,256,2) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv13 = nn.Conv2d(512,256,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv14 = nn.Conv2d(256,256,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.convtrans3 = nn.ConvTranspose2d(256,128,2) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv15 = nn.Conv2d(256,128,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv16 = nn.Conv2d(128,128,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.convtrans4 = nn.ConvTranspose2d(128,64,2) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv17 = nn.Conv2d(128,64,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv18 = nn.Conv2d(64,64,3) # (in_channels, out_channels, kernel_size)\n",
    "        self.conv19 = nn.Conv2d(64,2,1) # (in_channels, out_channels, kernel_size)        \n",
    "        self.maxpool = nn.MaxPool2d(2) # (kernel_size, stride, padding)   \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        out1 = F.relu(self.conv2(x))\n",
    "        out1_transform = nn.Upsample(size=(392, 392), mode='bilinear')(out1)\n",
    "        \n",
    "        x = self.maxpool(out1)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        out2 = F.relu(self.conv4(x))\n",
    "        out2_transform = nn.Upsample(size=(200, 200), mode='bilinear')(out2)\n",
    "        \n",
    "        x = self.maxpool(out2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        out3 = F.relu(self.conv6(x))\n",
    "        out3_transform = nn.Upsample(size=(104, 104), mode='bilinear')(out3)\n",
    "        \n",
    "        x = self.maxpool(out3)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        out4 = F.relu(self.conv8(x))\n",
    "        out4_transform = nn.Upsample(size=(56, 56), mode='bilinear')(out4)\n",
    "        \n",
    "        x = self.maxpool(out4)\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        out5 = self.convtrans1(x)\n",
    "        out5_transform = nn.Upsample(size=(56, 56), mode='bilinear')(out5)\n",
    "        \n",
    "        print(out4_transform.shape)\n",
    "        print(out5.shape)\n",
    "        \n",
    "        x = F.relu(self.conv11(torch.cat((out4_transform,out5_transform), 1)))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        out6 = self.convtrans2(x)\n",
    "        out6_transform = nn.Upsample(size=(104, 104), mode='bilinear')(out6)\n",
    "        \n",
    "        print(out3_transform.shape)\n",
    "        print(out6.shape)\n",
    "        \n",
    "        x = F.relu(self.conv13(torch.cat((out3_transform,out6_transform), 1)))\n",
    "        x = F.relu(self.conv14(x))\n",
    "        out7 = self.convtrans3(x)\n",
    "        out7_transform = nn.Upsample(size=(200, 200), mode='bilinear')(out7)\n",
    "        \n",
    "        print(out2_transform.shape)\n",
    "        print(out7.shape)\n",
    "        \n",
    "        x = F.relu(self.conv15(torch.cat((out2_transform,out7_transform), 1)))\n",
    "        x = F.relu(self.conv16(x))\n",
    "        out8 = self.convtrans4(x)\n",
    "        out8_transform = nn.Upsample(size=(392, 392), mode='bilinear')(out8)\n",
    "        \n",
    "        print(out1_transform.shape)\n",
    "        print(out8.shape)\n",
    "        \n",
    "        x = F.relu(self.conv17(torch.cat((out1_transform,out8_transform), 1)))\n",
    "        x = F.relu(self.conv18(x))\n",
    "        x = F.relu(self.conv19(x))\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_inst = unet().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 574, 574])\n"
     ]
    }
   ],
   "source": [
    "img = torch.from_numpy(np.zeros((574,574))).float().unsqueeze_(0)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shuja\\anaconda3\\envs\\venv-kaggle\\lib\\site-packages\\torch\\nn\\functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 56, 56])\n",
      "torch.Size([1, 512, 29, 29])\n",
      "torch.Size([1, 256, 104, 104])\n",
      "torch.Size([1, 256, 53, 53])\n",
      "torch.Size([1, 128, 200, 200])\n",
      "torch.Size([1, 128, 101, 101])\n",
      "torch.Size([1, 64, 392, 392])\n",
      "torch.Size([1, 64, 197, 197])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-03 *\n",
       "       [[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 6.7505,  6.8766,  6.8726,  ...,  6.8507,  6.8471,  6.7724],\n",
       "          [ 6.6623,  6.7422,  6.7122,  ...,  6.6760,  6.6658,  6.5747],\n",
       "          [ 6.6249,  6.6822,  6.6259,  ...,  6.5896,  6.5803,  6.5006],\n",
       "          ...,\n",
       "          [ 6.5805,  6.6454,  6.5919,  ...,  6.5525,  6.5532,  6.4831],\n",
       "          [ 6.5576,  6.6463,  6.5925,  ...,  6.5428,  6.5348,  6.4673],\n",
       "          [ 6.5626,  6.6432,  6.5915,  ...,  6.5410,  6.5283,  6.4575]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_inst(img.unsqueeze_(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
